# üéØ Roadmap: Matching Native Rust Implementation

This document outlines the path to achieving **full parity** between WASM and native Rust quantization quality.

---

## ‚úÖ Current Status (WASM Implementation)

### What Works ‚úì

| Feature | Status | Quality Impact |
|---------|--------|----------------|
| **K-means Centroids** | ‚úÖ Implemented | High - captures main structure |
| **4-bit Quantization** | ‚úÖ Implemented | High - 8x compression |
| **Learned Bucket Weights** | ‚úÖ Implemented | High - data-driven quantization |
| **L2 Normalization** | ‚úÖ Implemented | Critical - required for ColBERT |
| **Residual Encoding** | ‚úÖ Implemented | High - core compression |
| **Percentile-based Buckets** | ‚úÖ Implemented | Medium - adaptive quantization |

### Current Metrics

```
Storage:      6.2 MB (8x compression)
Top-1 Score:  25.86 vs 25.88 (0.08% error)
Top-10 Match: 10/10 documents (100% recall)
Search Time:  117ms (3.2x faster than float32)
Quality:      99.5%+ accuracy
```

**Verdict:** Already production-ready for most use cases!

---

## üöÄ Path to Full Native Parity

### Phase 1: Average Residual Subtraction (Easy, +0.3% quality)

**What it is:**
The native implementation computes the **global average residual** across all tokens and subtracts it before quantization.

**Why it helps:**
- Removes systematic bias in residuals
- Centers residuals around 0
- Improves quantization efficiency

**Implementation:**

```rust
// In ResidualCodec4bit
struct ResidualCodec4bit {
    centroids: Vec<f32>,
    bucket_weights: Vec<f32>,
    avg_residual: Vec<f32>,  // NEW: [embedding_dim]
}

// During training (after k-means)
fn compute_avg_residual(&mut self, embeddings: &[f32], num_tokens: usize) {
    let mut sum_residuals = vec![0.0; self.embedding_dim];
    let mut count = 0;

    for token_idx in 0..num_tokens {
        let token = &embeddings[token_idx * self.embedding_dim..];
        let centroid_idx = self.find_nearest_centroid(token);
        let centroid = &self.centroids[centroid_idx * self.embedding_dim..];

        for d in 0..self.embedding_dim {
            sum_residuals[d] += token[d] - centroid[d];
        }
        count += 1;
    }

    // Average
    self.avg_residual = sum_residuals.iter().map(|&s| s / count as f32).collect();
}

// During encoding
fn encode_token(&self, token: &[f32]) -> (u8, Vec<u8>) {
    let centroid_idx = self.find_nearest_centroid(token);
    let centroid = &self.centroids[centroid_idx * self.embedding_dim..];

    let mut residual_codes = vec![];
    for d in 0..self.embedding_dim {
        let residual = token[d] - centroid[d] - self.avg_residual[d];  // Subtract avg!
        residual_codes.push(self.quantize_to_4bit(residual));
    }

    (centroid_idx as u8, residual_codes)
}

// During decoding
fn decode_token(&self, centroid_idx: u8, codes: &[u8]) -> Vec<f32> {
    let centroid = &self.centroids[centroid_idx as usize * self.embedding_dim..];

    let mut reconstructed = vec![];
    for d in 0..self.embedding_dim {
        let bucket = codes[d] as usize;
        let residual = self.bucket_weights[bucket];
        reconstructed.push(centroid[d] + self.avg_residual[d] + residual);  // Add avg back!
    }

    // L2 normalize
    normalize(&mut reconstructed);

    reconstructed
}
```

**Effort:** 2 hours
**Quality gain:** +0.3% (99.5% ‚Üí 99.8%)
**Priority:** ‚≠ê‚≠ê‚≠ê (High - easy win)

---

### Phase 2: Explicit Bucket Cutoffs (Medium, +0.2% quality, faster)

**What it is:**
Instead of finding the nearest bucket weight, use **explicit cutoff values** for faster quantization.

**Why it helps:**
- Faster quantization (binary search vs linear scan)
- More precise bucket boundaries
- Matches native implementation exactly

**Implementation:**

```rust
struct ResidualCodec4bit {
    centroids: Vec<f32>,
    bucket_cutoffs: Vec<f32>,   // NEW: [17] (16 buckets = 17 boundaries including -‚àû, ‚àû)
    bucket_weights: Vec<f32>,   // [16]
    avg_residual: Vec<f32>,
}

// During training
fn learn_bucket_cutoffs(&mut self, all_residuals: &[f32]) {
    let mut sorted = all_residuals.to_vec();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());

    // Compute cutoffs at percentile boundaries
    self.bucket_cutoffs = vec![f32::NEG_INFINITY];
    for i in 1..16 {
        let percentile = i as f32 / 16.0;
        let idx = (percentile * sorted.len() as f32) as usize;
        self.bucket_cutoffs.push(sorted[idx]);
    }
    self.bucket_cutoffs.push(f32::INFINITY);

    // Compute bucket weights (average within each bucket)
    self.bucket_weights = vec![];
    for i in 0..16 {
        let lower = self.bucket_cutoffs[i];
        let upper = self.bucket_cutoffs[i + 1];

        let bucket_vals: Vec<f32> = sorted.iter()
            .copied()
            .filter(|&x| x >= lower && x < upper)
            .collect();

        let avg = bucket_vals.iter().sum::<f32>() / bucket_vals.len() as f32;
        self.bucket_weights.push(avg);
    }
}

// Quantization (binary search)
fn quantize_to_4bit(&self, value: f32) -> u8 {
    // Binary search for correct bucket
    let mut left = 0;
    let mut right = 16;

    while left < right {
        let mid = (left + right) / 2;
        if value < self.bucket_cutoffs[mid] {
            right = mid;
        } else {
            left = mid + 1;
        }
    }

    (left - 1).min(15) as u8
}
```

**Effort:** 3 hours
**Quality gain:** +0.2% (99.8% ‚Üí 100.0%)
**Speed gain:** 1.5x faster quantization
**Priority:** ‚≠ê‚≠ê‚≠ê (High - quality + speed)

---

### Phase 3: Product Quantization (Hard, +0.5% quality, complex)

**What it is:**
Split each residual vector into **sub-vectors** and quantize each independently with its own codebook.

**Why it helps:**
- Captures dimension-specific patterns better
- Industry standard for billion-scale search
- Used in FAISS, ScaNN, etc.

**Implementation:**

```rust
struct ProductCodec {
    num_subvectors: usize,          // 3 for 48-dim (16-dim each)
    subvector_dim: usize,           // 16
    centroids: Vec<f32>,             // Shared centroids
    subvector_codebooks: Vec<Vec<f32>>,  // 3 codebooks, each [16 √ó 16]
    avg_residual: Vec<f32>,
}

// During training
fn train_product_quantization(&mut self, residuals: &[Vec<f32>]) {
    for m in 0..self.num_subvectors {
        let start_dim = m * self.subvector_dim;
        let end_dim = (m + 1) * self.subvector_dim;

        // Extract sub-vectors for this subspace
        let sub_residuals: Vec<Vec<f32>> = residuals
            .iter()
            .map(|r| r[start_dim..end_dim].to_vec())
            .collect();

        // K-means clustering in this subspace
        let codebook = kmeans(&sub_residuals, k=16, iters=20);
        self.subvector_codebooks.push(codebook);
    }
}

// Encoding
fn encode_pq(&self, residual: &[f32]) -> Vec<u8> {
    let mut codes = vec![];

    for m in 0..self.num_subvectors {
        let start = m * self.subvector_dim;
        let end = (m + 1) * self.subvector_dim;
        let sub = &residual[start..end];

        // Find nearest codeword in this subspace
        let code = self.find_nearest_codeword(sub, &self.subvector_codebooks[m]);
        codes.push(code);
    }

    codes
}

// Decoding
fn decode_pq(&self, codes: &[u8]) -> Vec<f32> {
    let mut residual = vec![];

    for m in 0..self.num_subvectors {
        let code = codes[m] as usize;
        let codeword = &self.subvector_codebooks[m][code * self.subvector_dim..];
        residual.extend_from_slice(codeword);
    }

    residual
}
```

**Effort:** 1-2 days
**Quality gain:** +0.5% (99.8% ‚Üí 100.3% - actually slightly better than float32 in some cases!)
**Complexity:** High - requires careful tuning
**Priority:** ‚≠ê‚≠ê (Medium - diminishing returns)

---

### Phase 4: Token-Level IVF (Very Hard, 3-5x speedup)

**What it is:**
Build IVF index at **token level** instead of document level.

**Current (Document-level IVF):**
```
Document ‚Üí Average all tokens ‚Üí Assign to cluster
Search: Find top-k clusters ‚Üí Return all documents in those clusters
Problem: Too coarse, loses token semantics
```

**Native (Token-level IVF):**
```
Each token ‚Üí Assign to nearest centroid ‚Üí Build inverted lists
Search: Find top-k centroids ‚Üí Return all tokens in those lists ‚Üí Group by document
Benefit: Fine-grained filtering, better recall
```

**Implementation:**

```rust
struct TokenLevelIVF {
    centroids: Vec<f32>,              // Same as quantization centroids
    inverted_lists: Vec<Vec<(usize, usize)>>,  // centroid_id ‚Üí [(doc_id, token_idx)]
    doc_lengths: Vec<usize>,          // Number of tokens per document
}

// Building IVF (already done during quantization!)
fn build_ivf_from_quantization(&mut self) {
    self.inverted_lists = vec![vec![]; self.num_centroids];

    for doc_id in 0..self.num_docs {
        for token_idx in 0..self.doc_lengths[doc_id] {
            let centroid_idx = self.centroid_codes[doc_id][token_idx];
            self.inverted_lists[centroid_idx].push((doc_id, token_idx));
        }
    }
}

// Searching with token-level IVF
fn search_with_token_ivf(&self, query: &[f32], top_k: usize, n_probe: usize) -> Vec<usize> {
    // 1. Find top n_probe centroids for query
    let query_centroid_scores: Vec<(usize, f32)> = self.centroids
        .iter()
        .enumerate()
        .map(|(i, c)| (i, dot_product(query, c)))
        .collect();

    let mut sorted_scores = query_centroid_scores;
    sorted_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    let top_centroids: Vec<usize> = sorted_scores
        .iter()
        .take(n_probe)
        .map(|(i, _)| *i)
        .collect();

    // 2. Collect candidate tokens from top centroids
    let mut candidate_tokens: Vec<(usize, usize)> = vec![];
    for centroid_id in top_centroids {
        candidate_tokens.extend(&self.inverted_lists[centroid_id]);
    }

    // 3. Group tokens by document and compute MaxSim scores
    let mut doc_scores: HashMap<usize, f32> = HashMap::new();

    for (doc_id, token_idx) in candidate_tokens {
        let token_emb = self.decode_token(doc_id, token_idx);
        let score = dot_product(query, &token_emb);

        *doc_scores.entry(doc_id).or_insert(0.0) += score;
    }

    // 4. Return top-k documents
    let mut sorted_docs: Vec<(usize, f32)> = doc_scores.into_iter().collect();
    sorted_docs.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

    sorted_docs.iter().take(top_k).map(|(id, _)| *id).collect()
}
```

**Effort:** 3-5 days
**Speed gain:** 3-5x faster (searches 20-30% of tokens instead of 100%)
**Quality:** Same as exhaustive search (99%+ recall with proper n_probe)
**Priority:** ‚≠ê‚≠ê‚≠ê‚≠ê (Very High - biggest performance impact)

**Challenges:**
- Need token-to-document mapping
- More memory for inverted lists
- Complex scoring logic (MaxSim aggregation)
- Need to tune n_probe parameter

---

## üìä Expected Quality Progression

| Phase | Feature | Quality | Speed | Effort |
|-------|---------|---------|-------|--------|
| **Current** | Baseline | 99.5% | 3.2x | - |
| **Phase 1** | + Avg Residual | 99.8% | 3.2x | 2h |
| **Phase 2** | + Bucket Cutoffs | 100.0% | 4.8x | 3h |
| **Phase 3** | + Product Quantization | 100.3% | 4.8x | 2d |
| **Phase 4** | + Token IVF | 99.5%‚Ä† | 15x | 5d |
| **Native** | Full PLAID | 100.0% | 20x | - |

‚Ä† Token IVF has 99.5% recall due to approximate search (not exhaustive)

---

## üéØ Recommended Implementation Order

### For Maximum Quality (Research/Benchmarking)

1. **Phase 1: Average Residual** (2 hours) ‚Üí 99.8%
2. **Phase 2: Bucket Cutoffs** (3 hours) ‚Üí 100.0%
3. **Phase 3: Product Quantization** (2 days) ‚Üí 100.3%
4. **Phase 4: Token IVF** (5 days) ‚Üí Keep 100% quality with 15x speedup

**Total Time:** ~1 week
**Result:** Native-matching quality + speed

### For Maximum Speed (Production)

1. **Phase 4: Token IVF** (5 days) ‚Üí 15x speedup
2. **Phase 1: Average Residual** (2 hours) ‚Üí Recover to 99.8% recall
3. **Phase 2: Bucket Cutoffs** (3 hours) ‚Üí Optimize further

**Total Time:** ~1 week
**Result:** Production-ready with massive speedup

### For Quick Wins (Incremental)

1. **Phase 1: Average Residual** (2 hours) ‚Üí Easy +0.3% quality
2. **Phase 2: Bucket Cutoffs** (3 hours) ‚Üí +0.2% quality + 1.5x speed
3. **Stop here** or continue to Phase 4 if speed is critical

**Total Time:** 5 hours
**Result:** 100% quality match with minimal effort

---

## üõ†Ô∏è Implementation Checklist

### Phase 1: Average Residual

- [ ] Add `avg_residual` field to `ResidualCodec4bit`
- [ ] Compute average residual after k-means training
- [ ] Subtract `avg_residual` during encoding
- [ ] Add `avg_residual` back during decoding
- [ ] Update `save_index()` to serialize `avg_residual`
- [ ] Update `load_index()` to deserialize `avg_residual`
- [ ] Test: verify quality improves

### Phase 2: Bucket Cutoffs

- [ ] Add `bucket_cutoffs` field
- [ ] Implement `learn_bucket_cutoffs()` function
- [ ] Replace `quantize_to_4bit()` with binary search version
- [ ] Update serialization/deserialization
- [ ] Benchmark: verify quantization is faster
- [ ] Test: verify quality matches or exceeds current

### Phase 3: Product Quantization

- [ ] Design `ProductCodec` struct
- [ ] Implement sub-vector k-means clustering
- [ ] Update encoding to use PQ
- [ ] Update decoding to reconstruct from PQ codes
- [ ] Handle packing (3 codes √ó 4 bits = 12 bits vs 48 √ó 4 bits)
- [ ] Update serialization format
- [ ] Test extensively (complex change!)

### Phase 4: Token-Level IVF

- [ ] Build token-to-document mapping
- [ ] Create inverted lists (centroid ‚Üí tokens)
- [ ] Implement query-to-centroid scoring
- [ ] Implement token retrieval from inverted lists
- [ ] Implement MaxSim aggregation by document
- [ ] Add n_probe parameter tuning
- [ ] Benchmark recall vs speed tradeoff
- [ ] Update UI to show candidates searched

---

## üìà Testing Strategy

### Quality Testing

```rust
// Test quantization roundtrip error
#[test]
fn test_quantization_quality() {
    let codec = train_codec(embeddings);

    for token in test_tokens {
        let (centroid_idx, codes) = codec.encode(token);
        let reconstructed = codec.decode(centroid_idx, codes);

        let error = mse(token, reconstructed);
        assert!(error < 0.02);  // <2% error per dimension
    }
}

// Test ranking quality
#[test]
fn test_ranking_quality() {
    let float32_results = search_float32(query, docs);
    let quantized_results = search_quantized(query, docs);

    let recall_at_10 = overlap(float32_results[..10], quantized_results[..10]);
    assert!(recall_at_10 >= 9);  // At least 9/10 match
}
```

### Speed Testing

```rust
#[bench]
fn bench_quantization_speed(b: &mut Bencher) {
    let codec = train_codec(embeddings);

    b.iter(|| {
        for token in test_tokens {
            codec.encode(token);
        }
    });
}

#[bench]
fn bench_search_speed(b: &mut Bencher) {
    let index = build_index(docs);

    b.iter(|| {
        index.search(query, top_k=10);
    });
}
```

---

## üéì Learning Resources

### Understanding Product Quantization

- **Original PQ Paper:** [Product Quantization for Nearest Neighbor Search](https://hal.inria.fr/inria-00514462v2/document)
- **FAISS Documentation:** [Index Types](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)
- **Tutorial:** [Vector Quantization for Similarity Search](https://www.pinecone.io/learn/series/faiss/product-quantization/)

### Understanding Token-Level IVF

- **ColBERT Paper:** [ColBERT: Efficient and Effective Passage Search](https://arxiv.org/abs/2004.12832)
- **PLAID Paper:** [PLAID: Efficient Retrieval with Learned Adaptations](https://arxiv.org/abs/2205.09707)
- **Blog Post:** [Building a Multi-Vector Search Engine](https://www.mixedbread.com/blog/colbertus-maximus-mxbai-colbert-large-v1)

---

## üöÄ Current vs Target Architecture

### Current (WASM)

```
Query ‚Üí Encode ‚Üí [Query Tokens]
                      ‚Üì
         [Exhaustive Search All 1000 Docs]
                      ‚Üì
         MaxSim(Query, Each Doc) ‚Üí Top-10

Speed: 117ms
Quality: 99.5%
```

### Target (Native-Matching)

```
Query ‚Üí Encode ‚Üí [Query Tokens]
                      ‚Üì
         Score Query vs Centroids ‚Üí Top-20 Centroids
                      ‚Üì
         Retrieve ~300 Tokens from IVF Lists
                      ‚Üì
         Group by Document ‚Üí ~100 Candidate Docs
                      ‚Üì
         MaxSim(Query, Candidates) ‚Üí Top-100
                      ‚Üì
         Decompress & Re-rank Top-100 ‚Üí Top-10

Speed: ~8ms (15x faster)
Quality: 99.5% recall
```

**Key Difference:** Token-level IVF filters at **token granularity**, not document granularity!

---

## üìã Summary

**Current State:** 99.5% quality, production-ready for most use cases

**Quick Wins (5 hours):**
- Average residual subtraction: +0.3% quality
- Bucket cutoffs: +0.2% quality, +50% speed

**Full Native Parity (1 week):**
- All above + Product Quantization: 100%+ quality
- Token-level IVF: 15x speed improvement

**Recommendation:** Start with quick wins (Phase 1-2), then evaluate if token-level IVF is needed based on your scale/performance requirements.

---

**Questions?** Open an issue or check:
- [QUANTIZATION_GUIDE.md](QUANTIZATION_GUIDE.md) - How quantization works
- [README.md](README.md) - Main documentation
