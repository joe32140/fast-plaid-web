# FastPlaid WASM Demo with mxbai-edge-colbert-v0-17m

This demo showcases FastPlaid running in WebAssembly with integration for the mixedbread-ai/mxbai-edge-colbert-v0-17m model.

## Features

- âœ… **Pure WASM Implementation**: FastPlaid compiled to WebAssembly for browser execution
- âœ… **mxbai-edge-colbert Integration**: 17M parameter ColBERT model optimized for edge deployment
- âœ… **ColBERT MaxSim Scoring**: Token-level similarity with proper MaxSim aggregation
- âœ… **Real-time Search**: Encode queries and search documents entirely in the browser
- âœ… **No Server Required**: Complete semantic search pipeline runs offline

## Architecture

```
Text Query â†’ mxbai-edge-colbert â†’ Token Embeddings â†’ FastPlaid WASM â†’ Ranked Results
```

### Components

1. **mxbai-edge-colbert-v0-17m**: Compact ColBERT model (384-dim embeddings)
2. **FastPlaid**: Efficient vector search with IVF clustering + residual quantization
3. **WASM Runtime**: Browser-native execution without server dependencies

## Running the Demo

1. **Install dependencies**:
   ```bash
   npm install
   ```

2. **Serve the files**: Use the provided server with CORS headers
   ```bash
   # Using the provided Python server (recommended)
   python3 serve.py
   
   # Or use any HTTP server with CORS support
   python3 -m http.server 8000
   ```

3. **Open in browser**: Navigate to `http://localhost:8000`

3. **Follow the steps**:
   - Initialize WASM Module (loads FastPlaid + mxbai-edge-colbert)
   - Load Sample Index (creates document embeddings)
   - Search (encode query and find similar documents)

## Technical Details

- **Model**: mixedbread-ai/mxbai-edge-colbert-v0-17m (17M parameters)
- **Embedding Dimension**: 384 (optimized for edge deployment)
- **Max Sequence Length**: 512 tokens
- **Search Algorithm**: ColBERT MaxSim scoring
- **Index Type**: FastPlaid with quantized residuals
- **Runtime**: Pure WebAssembly (no server calls)

## Sample Documents

The demo includes 8 sample documents about machine learning topics:
- Introduction to Machine Learning
- Deep Learning Algorithms Overview
- Neural Networks and Backpropagation
- Supervised Learning Techniques
- Unsupervised Learning Methods
- Natural Language Processing with Transformers
- Computer Vision and Convolutional Networks
- Reinforcement Learning Fundamentals

## Implementation Status

### âœ… Completed
- WASM compilation and basic API
- **Real mxbai-edge-colbert integration with pylate-rs**
- **Automatic model loading from Hugging Face Hub**
- ColBERT MaxSim scoring with real embeddings
- End-to-end search pipeline
- Browser demo with UI
- Fallback to simulation mode if model loading fails

### ðŸ”„ Next Steps (for production)
- Implement full FastPlaid tensor operations with Candle
- Add proper index serialization/deserialization
- Optimize WASM bundle size and model caching
- Add support for larger document collections
- Implement incremental index updates

## Files

- `index.html`: Main demo interface
- `mxbai-integration.js`: mxbai-edge-colbert integration layer
- `pkg/`: Generated WASM package from Rust code
- `../rust/lib_wasm.rs`: WASM-specific Rust implementation

## Performance

The demo shows the potential for:
- **Fast query encoding**: ~10-50ms for typical queries
- **Efficient search**: Sub-second search over thousands of documents
- **Low memory usage**: Quantized index reduces memory footprint
- **Offline capability**: No network requests after initial load

This demonstrates how modern edge AI models like mxbai-edge-colbert can be combined with efficient search algorithms like FastPlaid to create powerful, offline semantic search experiences in the browser.